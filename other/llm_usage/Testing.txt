user: these are the tests we conducted for our US election predcition paper: 

library(tidyverse)
library(testthat)
library(arrow)
library(readr)

# loading the data #
simulated_data <-
  read_csv("data/00-simulated_data/simulated_data.csv")

# Checking data load success
if (exists("simulated_data") && is.data.frame(simulated_data)) {
  cat("Data load test passed: Dataset is loaded successfully and is a data frame.\n")
} else {
  stop("Data load test failed: Dataset is not loaded or is not a data frame.\n")
}

# Checking for any missing values
if (all(!is.na(simulated_data))) {
  cat("No missing values in the dataset.\n")
} else {
  cat("There are missing values in the dataset.\n")
}

# Checking for valid state names
valid_states <-
  c(
    "Alabama",
    "Alaska",
    "Arizona",
    "Arkansas",
    "California",
    "Colorado",
    "Connecticut",
    "Delaware",
    "Florida",
    "Georgia",
    "Hawaii",
    "Idaho",
    "Illinois",
    "Indiana",
    "Iowa",
    "Kansas",
    "Kentucky",
    "Louisiana",
    "Maine",
    "Maryland",
    "Massachusetts",
    "Michigan",
    "Minnesota",
    "Mississippi",
    "Missouri",
    "Montana",
    "Nebraska",
    "Nevada",
    "New Hampshire",
    "New Jersey",
    "New Mexico",
    "New York",
    "North Carolina",
    "North Dakota",
    "Ohio",
    "Oklahoma",
    "Oregon",
    "Pennsylvania",
    "Rhode Island",
    "South Carolina",
    "South Dakota",
    "Tennessee",
    "Texas",
    "Utah",
    "Vermont",
    "Virginia",
    "Washington",
    "West Virginia",
    "Wisconsin",
    "Wyoming"
  )

if (all(simulated_data$state %in% valid_states)) {
  cat("All values in 'state' column are valid US state names.\n")
} else {
  cat("The 'state' column contains invalid state names.\n")
}


# Testing data set shape
test_that("Data shape is correct", {
  expect_equal(ncol(simulated_data), 13) # Expected number of columns
  expect_equal(nrow(simulated_data), 100) # Expected number of rows
})

# Testing ID and grade ranges
test_that("ID and grade ranges are within expected limits", {
  expect_true(all(simulated_data$poll_id >= 1 &
                    simulated_data$poll_id <= 1000))
  expect_true(all(
    simulated_data$pollster_id >= 1 &
      simulated_data$pollster_id <= 100
  ))
  expect_true(all(
    simulated_data$numeric_grade >= 0.0 &
      simulated_data$numeric_grade <= 10.0
  ))
  expect_true(all(simulated_data$pollscore >= -1 &
                    simulated_data$pollscore <= 1))
})

# Testing methodology column values
test_that("Methodology column contains valid values", {
  expect_true(all(
    simulated_data$methodology %in% c("Online", "In-Person", "Hybrid")
  ))
})

# Test sample sizes and percentage values
test_that("Sample sizes and pct are within expected ranges", {
  expect_true(all(
    simulated_data$sample_size >= 100 &
      simulated_data$sample_size <= 10000
  ))
  expect_true(all(simulated_data$pct >= 30 &
                    simulated_data$pct <= 70))
})

# Test population column values
test_that("Population column contains valid types", {
  expect_true(all(
    simulated_data$population %in% c("likely voters", "registered voters")
  ))
})

# Test candidate_name values
test_that("Candidate names are valid", {
  expect_true(all(
    simulated_data$candidate_name %in% c("Donald Trump", "Kamala Harris", "other")
  ))

the dataset looked like the image attached, the image is a sample of the whole dataset we simulated.  

and the professor said that this was a 'limited number of tests' and gave us 3/4 marks. 

chatgpt: 

Thank you for sharing the example tests and the feedback from your professor. To improve your score and create a more comprehensive test suite for the simulated housing dataset, weâ€™ll need to expand on these ideas. Here's what I propose:

---

### **Testing Goals**
1. **Data Load Tests**:
   - Ensure the dataset is loaded properly and is a data frame.
2. **Missing Values Tests**:
   - Check if any columns or rows contain missing values.
3. **Column Names Validation**:
   - Verify that all column names match the expected names.
4. **Data Type Validation**:
   - Ensure each column has the correct data type (e.g., `Date` for `date`, `numeric` for others).
5. **Range and Value Tests**:
   - Validate that simulated values fall within reasonable ranges:
     - CPI values, interest rates, house prices, etc.
6. **Dataset Shape**:
   - Confirm the number of rows and columns matches expectations.
7. **Trend Consistency Tests**:
   - Verify that certain columns (e.g., CPI, house prices) exhibit trends or reasonable variation over time.

---

### **Expanded Test Script for Simulated Housing Data**
Hereâ€™s an improved set of tests for your housing dataset:

```R
# Load required libraries
library(testthat)
library(dplyr)

# Load the simulated dataset
simulated_data <- simulated_data  # Assuming it is already loaded in your environment

# 1. Test: Dataset load success
test_that("Dataset loads successfully", {
  expect_true(exists("simulated_data") && is.data.frame(simulated_data))
})

# 2. Test: No missing values
test_that("No missing values in dataset", {
  expect_true(all(!is.na(simulated_data)))
})

# 3. Test: Column names are correct
test_that("Column names are as expected", {
  expected_names <- c("date", "cpi", "interest_rates", "house_prices", "average_wages", "house_supply")
  expect_equal(colnames(simulated_data), expected_names)
})

# 4. Test: Column data types are correct
test_that("Column data types are correct", {
  expect_true(is.Date(simulated_data$date))              # Date column
  expect_true(is.numeric(simulated_data$cpi))            # CPI column
  expect_true(is.numeric(simulated_data$interest_rates)) # Interest rates
  expect_true(is.numeric(simulated_data$house_prices))   # House prices
  expect_true(is.numeric(simulated_data$average_wages))  # Average wages
  expect_true(is.numeric(simulated_data$house_supply))   # House supply
})

# 5. Test: Value ranges for each column
test_that("Values fall within expected ranges", {
  expect_true(all(simulated_data$cpi >= 200 & simulated_data$cpi <= 400))               # CPI range
  expect_true(all(simulated_data$interest_rates >= 0 & simulated_data$interest_rates <= 10)) # Interest rates
  expect_true(all(simulated_data$house_prices >= 200000 & simulated_data$house_prices <= 600000)) # House prices
  expect_true(all(simulated_data$average_wages >= 20 & simulated_data$average_wages <= 50))      # Average wages
  expect_true(all(simulated_data$house_supply >= 4 & simulated_data$house_supply <= 12))         # House supply
})

# 6. Test: Dataset shape
test_that("Dataset shape is correct", {
  expect_equal(nrow(simulated_data), length(seq(as.Date("2006-03-01"), as.Date("2024-09-01"), by = "month"))) # Number of rows
  expect_equal(ncol(simulated_data), 6) # Number of columns
})

# 7. Test: Trend consistency (e.g., CPI generally increases over time)
test_that("CPI shows reasonable trends over time", {
  expect_true(median(diff(simulated_data$cpi)) >= 0) # Median change should be non-negative
})
```

---

### **Expanded Coverage**
This test suite includes:
1. **Additional Validation**:
   - Tests for proper column names, data types, and ranges.
2. **Trend Test**:
   - A basic check that CPI increases or stays stable over time, as expected.
3. **Shape Validation**:
   - Ensures the number of rows and columns are correct.

---

### **Next Steps**
1. Run this script in your R environment.
2. Make sure all tests pass for your simulated dataset.
3. Add more advanced trend tests or outlier detection if needed.

Let me know how it goes or if you'd like further refinements! ðŸ˜Š